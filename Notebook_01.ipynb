{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Introduction to Data-Centric AI and Weakly Supervised Learning\n",
    "## Learning with Limited Labels: Weak Supervision and Uncertainty-Aware Training\n",
    "### [Dr. Elias Jacob de Menezes Neto](https://docente.ufrn.br/elias.jacob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Logistics: A Few Things You Should Know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask Questions\n",
    "Please let me know how things are progressing for you throughout the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "**Office hours**: If you need to meet, please [email me](elias.jacob@ufrn.br)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Requirements for This Course\n",
    "To succeed in this course, you should have:\n",
    "\n",
    "- Access to the dataset and the code provided.\n",
    "- A foundational understanding of machine learning.\n",
    "- Basic knowledge of natural language processing (NLP).\n",
    "- Proficiency in Python.\n",
    "- Familiarity with Jupyter Notebooks.\n",
    "- Basic knowledge of statistics.\n",
    "- An understanding of data science and machine learning concepts and stacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching Approach\n",
    "#### Top-Down Method\n",
    "I will be employing a *top-down* teaching method, which contrasts the traditional *bottom-up* approach. In a *bottom-up* approach, you typically learn all the individual components first and then gradually combine them into more complex structures. This approach often leads to students losing motivation, lacking a sense of the \"big picture,\" and not knowing what they will need in practice.\n",
    "\n",
    "According to Harvard Professor David Perkins in his book [Making Learning Whole](https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719), effective learning can be likened to learning a sport like baseball. Children are not required to memorize all the rules and understand every technical detail before they start playing. Instead, they begin by playing with a general understanding and gradually learn more rules and details over time.\n",
    "\n",
    "#### Focus on Functionality\n",
    "At the beginning of this course, prioritize understanding what things **do**, not necessarily what they **are**. You will encounter some \"black boxes\"‚Äîconcepts or tools that we use without fully explaining them upfront. Later, we will get into the lower-level details.\n",
    "\n",
    "#### Learning by Doing and Explaining\n",
    "Research indicates that people learn best by:\n",
    "1. **Doing**: Engaging in coding and building projects.\n",
    "2. **Explaining**: Articulating what they've learned, either by writing or helping others.\n",
    "\n",
    "I will guide you through building projects and encourage you to explain these concepts to your peers.\n",
    "\n",
    "#### Learning as a Team Sport\n",
    "Studies show that teamwork significantly enhances learning. Therefore, I encourage you to:\n",
    "- Ask questions.\n",
    "- Answer questions from fellow students.\n",
    "- Collaborate on building projects.\n",
    "\n",
    "If you receive a request for help, consider it an opportunity to solidify your understanding by teaching others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Materials\n",
    "All course materials can be accessed at the course's GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Final Grade\n",
    "Your final grade will be based on a project that ideally employs data from a real-life project you are working on. The project will be evaluated on the following criteria:\n",
    "\n",
    "- **Technical Quality**: The effectiveness and accuracy of your implementation.\n",
    "- **Creativity**: The innovation and uniqueness of your approach.\n",
    "- **Usefulness**: The practical application and benefit of your project.\n",
    "- **Presentation**: The clarity and professionalism of your project presentation.\n",
    "\n",
    "#### FAQ\n",
    "> - The project must be completed individually.\n",
    "> - Submit a link to a shared folder containing your code, data, and report. Use virtual environments and a `requirements.txt` file to assist running your code.\n",
    "> - The project is due 15 days after the course ends.\n",
    "> - Submit your project through SIGAA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Keypoints\n",
    "\n",
    "- Data-Centric AI is a example shift in AI development, focusing on the critical role of data quality and quantity rather than solely on model architecture improvements.\n",
    "\n",
    "- The three key principles of Data-Centric AI are:\n",
    "1. It centers around data as the primary driver of AI success.\n",
    "2. It needs to be programmatic to overcome the limitations of manual data labeling.\n",
    "3. It requires the inclusion of subject matter expertise in the development process.\n",
    "\n",
    "- Weak supervision is a powerful technique for addressing the challenge of limited labeled data, leveraging domain knowledge and heuristics to create large-scale labeled datasets efficiently.\n",
    "\n",
    "- There are three primary types of weak supervision:\n",
    "1. Incomplete supervision: Only a subset of the training data is labeled.\n",
    "2. Inexact supervision: Labels are less precise or fine-grained than ideal.\n",
    "3. Inaccurate supervision: Labels contain errors or noise.\n",
    "\n",
    "- Weak supervision can achieve comparable or even superior performance to traditional supervised learning in various tasks, often requiring about twice as much weakly labeled data to match the performance of manually annotated datasets.\n",
    "\n",
    "- Aggregating multiple, potentially noisy labeling sources is a critical aspect of weak supervision, with techniques ranging from simple majority voting to advanced methods like graph neural networks and matrix completion.\n",
    "\n",
    "- Even widely used benchmark datasets contain significant labeling errors, underscoring the need for techniques to automatically detect and correct annotation errors in both human-annotated and weakly supervised datasets.\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "- The focus in AI development is shifting from model architecture to data quality and management, emphasizing the importance of data curation, augmentation, and governance in achieving high-performance AI systems.\n",
    "\n",
    "- Weak supervision offers a scalable and cost-effective alternative to traditional manual data labeling, particularly valuable in domains where expert knowledge is required or when dealing with large-scale datasets.\n",
    "\n",
    "- The effectiveness of weak supervision challenges the notion that only carefully hand-labeled datasets can produce high-quality machine learning models, opening up new possibilities for AI development in data-scarce or expertise-intensive domains.\n",
    "\n",
    "- Integrating subject matter experts into the AI development process is crucial for creating effective labeling functions and ensuring the relevance and accuracy of the resulting models.\n",
    "\n",
    "- The asymptotic scaling behavior of weak supervision methods matches that of traditional supervised learning, suggesting that effective use of unlabeled data can yield strong predictive performance similar to fully supervised methods.\n",
    "\n",
    "- As AI systems become more prevalent in critical applications, understanding and mitigating the impact of label noise and errors is increasingly important for ensuring the reliability and trustworthiness of these systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Centric AI: Shifting Focus from Models to Data\n",
    "\n",
    "## The Model Shift in AI Development\n",
    "\n",
    "In recent years, the field of Artificial Intelligence has undergone a significant transformation. While much attention has been focused on developing sophisticated models and architectures, a new example is emerging: Data-Centric AI. This approach recognizes that **data, not just algorithms, is the key driver of AI success**.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/model_vs_datacentric.jpeg\" width=\"70%\" height=\"70%\">\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "Consider the following two perspectives, assuming that $\\text{AI} = \\text{Code} + \\text{Data} $:\n",
    "\n",
    "- **Conventional model-centric approach**\n",
    "- Historically, AI development has been model-centric, with a primary focus on designing and optimizing algorithms.\n",
    "- Researchers have dedicated substantial effort to developing complex neural network architectures and training procedures.\n",
    "\n",
    "- **Emerging data-centric approach**\n",
    "- The data-centric approach emphasizes the critical role of data in AI development.\n",
    "- Recent advances in AI are often attributed to the availability of large, high-quality datasets rather than architectural innovations.\n",
    "\n",
    "Consider the evolution of language models, particularly the GPT series developed by OpenAI:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/gpt_evolution.png\" width=\"70%\" height=\"70%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "The [figure](http://arxiv.org/abs/2303.10158) above illustrates the evolution of the GPT series, from GPT-1 to GPT-3. Notably, the primary driver of performance improvements is the **scale of the model and the training data**. While architectural enhancements have been made, the key factor behind the models' success is the vast amount of data used to train them.\n",
    "\n",
    "- On the **left**, large and high-quality training data are the driving force of recent successes of GPT models, while model architectures remain similar, except for more model weights.\n",
    "- On the **right**, when the model becomes sufficiently powerful, we only need to engineer prompts (inference data) to accomplish our objectives, with the model being fixed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Principles of Data-Centric AI\n",
    "\n",
    "### Principle 1: It Centers Around Data\n",
    "1. **Data as the Primary Driver**\n",
    "\n",
    "- The adage \"Garbage In, Garbage Out\" (GIGO) is particularly relevant in AI, emphasizing the critical role of data quality.\n",
    "- Recent AI breakthroughs are largely attributed to the quality and quantity of data, rather than model architecture improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **The Power of Large Language Models**\n",
    "- With the advent of powerful models like GPT-3, the focus has shifted from model design to prompt engineering.\n",
    "- These models demonstrate that with sufficient scale and data, many complex tasks can be solved through clever prompting rather than architectural changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **The \"Solved\" Problem of Deep Learning Architectures**\n",
    "- Many researchers argue that the fundamental challenges in designing deep learning architectures have been largely addressed.\n",
    "- See the image below: over the last years the [performance on IMDB sentiment analysis](https://paperswithcode.com/sota/sentiment-analysis-on-imdb) has been increasing very modestly . After 5 years and millions of dollars invested, the accuracy has increased from 96.0% to 96.68%\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/imdb_sentiment_analysis.png\" width=\"70%\" height=\"70%\">\n",
    "</div>\n",
    "\n",
    "- The emphasis now is on applying and fine-tuning existing architectures rather than creating entirely new ones.\n",
    "- The \"problem\" with designing deep learning architectures is \"solved\". Today, you can load a pre-trained model with few lines of code and get state-of-the-art results. The real challenge is to get the right data to train your model.\n",
    "\n",
    "> <video width=\"720\" controls>\n",
    "> <source src=\"images/febraban1.mp4\" type=\"video/mp4\">\n",
    "> </video>\n",
    ">\n",
    "\n",
    "\n",
    "Maybe a little too much? Let's see.\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "````\n",
    "\n",
    "Maybe he was right. üòÖ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Data Hunger of Deep Learning Models**\n",
    "- Modern deep learning models require vast amounts of data to achieve high performance.\n",
    "- This data dependency has led to a shift in focus towards data acquisition, curation, and management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle 2: It Needs to be Programmatic\n",
    "\n",
    "#### The Challenge of Manual Data Labeling\n",
    "\n",
    "In the current landscape of AI development, a significant bottleneck exists in the form of manual data labeling. This process often requires:\n",
    "\n",
    "- Large teams of human labelers\n",
    "- Extensive time and resources\n",
    "- Specialized knowledge for domain-specific tasks\n",
    "\n",
    "While this approach has been necessary, it presents several critical limitations:\n",
    "\n",
    "1. **Scalability Issues**: As datasets grow larger and more complex, manual labeling becomes increasingly impractical.\n",
    "2. **Cost Inefficiency**: Hiring and maintaining large teams of labelers is expensive and often unsustainable for many organizations.\n",
    "3. **Time Constraints**: Manual labeling is time-consuming, slowing down the development and iteration of AI models.\n",
    "\n",
    "#### The Impracticality for Real-World Applications\n",
    "\n",
    "For many real-world AI applications, especially those dealing with sensitive or specialized data, manual labeling faces additional challenges:\n",
    "\n",
    "- **Data Privacy Concerns**: In fields like healthcare or law, data often contains sensitive personal information that cannot be easily shared with labelers.\n",
    "- **Expertise Requirements**: Certain domains require highly specialized knowledge for accurate labeling:\n",
    "- Legal cases need judges or lawyers\n",
    "- Medical data requires physicians or specialists\n",
    "- Technical fields may require subject matter experts\n",
    "\n",
    "> **Example**: Imagine developing an AI for rare disease diagnosis. Each case would need to be labeled by a specialist in that particular rare condition, making the process extremely time-consuming and expensive. This data may also be sensitive and require strict privacy measures, further complicating the labeling process.\n",
    "\n",
    "#### The Problem of Evolving Information\n",
    "\n",
    "One of the most significant issues with manual labeling is its static nature in a dynamic world:\n",
    "\n",
    "- **Rapid Information Changes**: New laws, medical discoveries, or technological advancements can quickly render existing labels obsolete.\n",
    "- **Continuous Updates Needed**: Adding new classes or modifying existing ones requires re-labeling large portions of the dataset.\n",
    "\n",
    "> **Analogy**: Think of manual labeling like printing a paper encyclopedia. By the time it's complete, some entries are already outdated, and adding new information requires reprinting the entire set.\n",
    "\n",
    "#### The Call for Programmatic Solutions\n",
    "\n",
    "To address these challenges, the field is moving towards more programmatic approaches to AI development:\n",
    "\n",
    "1. **Automated Labeling Techniques**: Developing algorithms that can label data with minimal human intervention.\n",
    "2. **Transfer Learning**: Employing knowledge from pre-trained models to reduce the need for extensive labeled datasets.\n",
    "3. **Active Learning**: Implementing systems that intelligently select the most informative samples for labeling, reducing overall labeling requirements.\n",
    "4. **Synthetic Data Generation**: Creating artificial datasets that mimic real-world data characteristics.\n",
    "\n",
    "These programmatic approaches offer several advantages:\n",
    "\n",
    "- **Scalability**: Can handle large and growing datasets more efficiently.\n",
    "- **Adaptability**: Easier to update and modify as new information becomes available.\n",
    "- **Cost-Effectiveness**: Reduces the need for large teams of human labelers.\n",
    "- **Speed**: Allows for faster development and iteration of AI models.\n",
    "\n",
    "To summarize:\n",
    "\n",
    "\n",
    "| Labeling approach | Speed | Cost | Adaptability |\n",
    "|---------------|-------|-----------|--------------|\n",
    "| Manual Labels | Slow | Expensive | Static |\n",
    "| Programmatic Labels | Fast | Cheap | Dynamic |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle 3: It Needs to Include Subject Matter Expertise in the Loop\n",
    "\n",
    "#### The Role of Subject Matter Experts (SMEs)\n",
    "\n",
    "In real-world machine learning projects, the involvement of Subject Matter Experts (SMEs) is not just beneficial‚Äîit's essential. Their deep domain knowledge provides critical context and insights that can significantly enhance the quality and relevance of your ML solutions.\n",
    "\n",
    "- **Project Reflection**: Consider your current or recent ML projects. How much time did you spend communicating with SMEs? This interaction is often more extensive than many anticipate, highlighting the importance of effective collaboration.\n",
    "\n",
    "#### SMEs as Team Members\n",
    "\n",
    "It's important to shift your perspective on SMEs:\n",
    "\n",
    "- **Not outsiders, but central team members**: SMEs should be viewed as indispensable parts of your ML project team.\n",
    "- **Develop communication skills**: Learning to effectively communicate with SMEs is as important as your technical skills. This involves:\n",
    "- Translating technical concepts into domain-specific language\n",
    "- Actively listening to their insights and concerns\n",
    "- Asking targeted questions to extract relevant information\n",
    "\n",
    "#### Navigating Domain Complexity\n",
    "\n",
    "As an ML practitioner, you'll encounter diverse industries and domains:\n",
    "\n",
    "- **Acknowledge limitations**: It's impossible to be an expert in every field your projects touch.\n",
    "- **Embrace continuous learning**: Don't let the vastness of domain knowledge discourage you. Each project is an opportunity to expand your understanding.\n",
    "- **Knowledge encoding**: Your primary task is to effectively translate SME knowledge into your ML models and processes.\n",
    "\n",
    "> **Key Point**: The goal is not to become an expert in every domain, but to develop the skills to extract, understand, and incorporate domain expertise into your ML solutions.\n",
    "\n",
    "#### Strategies for Effective SME Combination\n",
    "\n",
    "1. **Regular check-ins**: Schedule frequent meetings with SMEs throughout the project lifecycle.\n",
    "2. **Collaborative problem definition**: Involve SMEs in defining project objectives and success criteria.\n",
    "3. **Data interpretation**: Exploit SME insights for better understanding of data nuances and anomalies.\n",
    "4. **Feature engineering**: Work with SMEs to identify and create meaningful features that capture domain-specific nuances.\n",
    "5. **Model evaluation**: Incorporate SME feedback in assessing model performance beyond just metrics.\n",
    "6. **Iterative refinement**: Use SME input to continuously improve your models and approaches.\n",
    "\n",
    "#### Overcoming Challenges\n",
    "\n",
    "- **Bridging knowledge gaps**: Develop strategies to effectively communicate across disciplinary boundaries.\n",
    "- **Managing expectations**: Clearly articulate the capabilities and limitations of ML to SMEs.\n",
    "- **Balancing perspectives**: Learn to reconcile potentially conflicting viewpoints between technical feasibility and domain-specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Data-Centric Approach\n",
    "\n",
    "> \"Data is both the key bottleneck and interface to developing AI today\"\n",
    "\n",
    "This quote encapsulates the essence of Data-Centric AI. It suggests that:\n",
    "\n",
    "- **Data as a Bottleneck**: The limitation in AI development is often not computational power or model sophistication, but the availability of high-quality, relevant data.\n",
    "- **Data as an Interface**: Data serves as the primary means through which we interact with and shape AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repercussions and Strategies\n",
    "\n",
    "1. **Focus on Data Quality**\n",
    "- Prioritize collecting, cleaning, and curating high-quality datasets.\n",
    "- Implement robust data validation and verification processes.\n",
    "\n",
    "2. **Data Augmentation and Synthesis**\n",
    "- Develop techniques to artificially expand datasets while maintaining relevance and quality.\n",
    "- Explore methods for generating synthetic data to address scarcity in certain domains.\n",
    "\n",
    "3. **Efficient Data Labeling**\n",
    "- Investigate techniques like weak supervision and semi-supervised learning to reduce the need for extensive manual labeling.\n",
    "- Develop smart labeling tools that capitalize on existing models to assist in the labeling process.\n",
    "\n",
    "4. **Data Governance and Ethics**\n",
    "- Establish clear protocols for data collection, usage, and storage.\n",
    "- Address ethical concerns related to data bias, privacy, and representation.\n",
    "\n",
    "5. **Continuous Data Improvement**\n",
    "- Implement systems for ongoing data refinement and updates.\n",
    "- Develop metrics to assess and improve data quality over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and Considerations\n",
    "\n",
    "- **Balancing Quantity and Quality**: While more data is generally beneficial, it's crucial to maintain data quality and relevance.\n",
    "- **Domain Specificity**: The effectiveness of Data-Centric AI can vary across different domains and applications.\n",
    "- **Computational Resources**: Managing and processing large datasets requires significant computational resources.\n",
    "- **Interdisciplinary Approach**: Effective Data-Centric AI often requires collaboration between domain experts, data scientists, and AI researchers.\n",
    "\n",
    "> By embracing a Data-Centric approach, AI practitioners can potentially achieve significant improvements in model performance and applicability, often surpassing gains from model architecture tweaks alone. This shift represents a fundamental change in how we approach AI development, emphasizing the critical role of data in shaping the future of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I don't have enough data, what can I do?\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/insufficient_labeled_training_data.png\" width=\"70%\" height=\"70%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Supervised to Weakly Supervised Learning\n",
    "\n",
    "### Understanding Fully Supervised Learning\n",
    "\n",
    "Fully supervised learning (or just traditional supervision) is a fundamental concept in machine learning where we aim to learn a function that maps input features to output labels using a labeled dataset. This approach forms the basis for many practical applications in data science and machine learning.\n",
    "\n",
    "#### Key Components of Fully Supervised Learning\n",
    "\n",
    "1. **Function Mapping**: The key goal is to learn a function $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$\n",
    "- $\\mathcal{X}$ represents the input space (features)\n",
    "- $\\mathcal{Y}$ represents the output space (labels)\n",
    "- $f$ is the function that establishes the relationship between $\\mathcal{X}$ and $\\mathcal{Y}$\n",
    "\n",
    "2. **Dataset Structure**: We work with a dataset $\\mathcal{D} = \\{(x_1, y_1), ..., (x_m, y_m)\\}$\n",
    "- Each pair $(x_i, y_i)$ represents an input-output example\n",
    "- $x_i \\in \\mathcal{X}$: An instance from the input space\n",
    "- $y_i \\in \\mathcal{Y}$: The corresponding label from the output space\n",
    "\n",
    "3. **Output Space Variations**: The nature of $\\mathcal{Y}$ defines the type of supervised learning task:\n",
    "- Binary Classification: $\\mathcal{Y} = \\{\\text{Yes}, \\text{No}\\}$\n",
    "- Multiclass or Multilabel Classification: $\\mathcal{Y} = \\{\\text{Class}_1, \\text{Class}_2, ..., \\text{Class}_n\\}$\n",
    "- Regression: $\\mathcal{Y} = \\mathbb{R}$ (real numbers)\n",
    "\n",
    "#### The Learning Process\n",
    "\n",
    "1. **Data Collection**: Gather a representative dataset with input-output pairs.\n",
    "2. **Feature Selection**: Identify relevant attributes of the input space.\n",
    "3. **Model Selection**: Choose an appropriate algorithm or model architecture.\n",
    "4. **Training**: Use the labeled data to optimize the model's parameters.\n",
    "5. **Validation**: Assess the model's performance on unseen data.\n",
    "6. **Fine-tuning**: Adjust hyperparameters or model structure as needed.\n",
    "\n",
    "#### Objective Function\n",
    "\n",
    "In supervised learning, we typically aim to minimize a loss function $\\mathcal{L}$:\n",
    "\n",
    "$$\\min_{\\theta} \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(f_{\\theta}(x_i), y_i)$$\n",
    "\n",
    "Where:\n",
    "- $\\theta$ represents the model parameters\n",
    "- $f_{\\theta}(x_i)$ is the model's prediction for input $x_i$\n",
    "- $\\mathcal{L}(f_{\\theta}(x_i), y_i)$ measures the discrepancy between the prediction and true label\n",
    "\n",
    "> You could read that as \"Find the model settings that, on average, make our predictions as close as possible to the correct answers for all our training examples.\"\n",
    "\n",
    "#### Advantages and Challenges\n",
    "\n",
    "**Advantages:**\n",
    "- High accuracy when sufficient labeled data is available\n",
    "- Clear evaluation metrics based on predicted vs. actual labels\n",
    "- Well-established theoretical foundations and practical techniques\n",
    "\n",
    "**Challenges:**\n",
    "- Requires large amounts of labeled data, which can be expensive and time-consuming to obtain\n",
    "- May struggle with generalization if training data is not representative\n",
    "- Can be prone to overfitting, especially with complex models and limited data\n",
    "\n",
    "> **Note**: While fully supervised learning is powerful, it's important to recognize its limitations, particularly the need for large labeled datasets. This realization has led to the development of weakly supervised and unsupervised learning techniques, which we'll explore in subsequent sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Weak Supervision\n",
    "\n",
    "> *‚ÄúWeakly supervised learning is an umbrella term covering a variety of studies that attempt to construct predictive models by learning with weak supervision.‚Äù*\n",
    "\n",
    "Weak supervision in machine learning comes in several forms, each presenting unique challenges and methodologies. The three primary types are **incomplete supervision**, **inexact supervision**, and **inaccurate supervision**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Incomplete Supervision\n",
    "\n",
    "<img src=\"images/incomplete_supervision.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Incomplete supervision occurs when only a subset of the training data is labeled. This is a common scenario in real-world applications where labeling data can be expensive, time-consuming, or impractical.\n",
    "\n",
    "- **Characteristics**:\n",
    "- Only a subset of data points have labels.\n",
    "- A large portion of the data remains unlabeled.\n",
    "- Formally, we have $\\mathcal{l}$ labeled data points and $\\mathcal{u}$ unlabeled data points, with $\\mathcal{l} \\ll \\mathcal{u}$, totaling $\\mathcal{m} = \\mathcal{l} + \\mathcal{u}$ data points.\n",
    "\n",
    "$$ \\mathcal{D} = \\{(x_1, y_1), ..., (x_l, y_l), (x_{l+1}, \\emptyset), ..., (x_m, \\emptyset)\\} $$\n",
    "\n",
    "- **Example**: In a dataset of medical images, only a small fraction might be annotated by experts due to the high cost and time required for labeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inexact Supervision\n",
    "\n",
    "<img src=\"images/inexact_supervision.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Inexact supervision refers to situations where the labels provided are less precise or fine-grained than ideal. This often involves higher-level or aggregate information rather than specific, instance-level labels.\n",
    "\n",
    "- **Characteristics**:\n",
    "- Labels are present but lack precision or detail.\n",
    "- Often involves group or set-level annotations rather than individual instance labels.\n",
    "- May provide partial information about the target variable.\n",
    "\n",
    "- **Common Forms**:\n",
    "1. **Multiple Instance Learning (MIL)**:\n",
    "- Bags of instances are labeled, not individual instances.\n",
    "- Formally, for a bag $B_i = \\{x_{i1}, x_{i2}, ..., x_{in}\\}$, we have:\n",
    "$$ y_i = \\begin{cases}\n",
    "1 & \\text{if } \\exists x_{ij} \\in B_i : y_{ij} = 1 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "2. **Label Proportions**:\n",
    "- Only the proportion of positive instances in a group is known.\n",
    "- For a group $G_k$ with $n_k$ instances, we have:\n",
    "$$ p_k = \\frac{1}{n_k} \\sum_{x_i \\in G_k} y_i $$\n",
    "where $p_k$ is the known proportion of positive instances in group $k$.\n",
    "\n",
    "3. **Coarse-Grained Labels**:\n",
    "- Labels are provided at a higher level of granularity than desired.\n",
    "- If $Y$ is the set of fine-grained labels and $Z$ is the set of coarse-grained labels:\n",
    "$$ z = f(y), \\text{ where } y \\in Y, z \\in Z, \\text{ and } |Z| < |Y| $$\n",
    "\n",
    "\n",
    "- **Examples**:\n",
    "- **Image Classification**: An image is labeled as containing a cat, but the exact location of the cat is unknown.\n",
    "- **Text Analysis**: A document is labeled as positive or negative, but the specific sentences contributing to this sentiment are not indicated.\n",
    "- **Epidemiology**: Data on disease prevalence in a population without individual diagnoses.\n",
    "\n",
    "\n",
    "> **Note**: Inexact supervision is often used as part of a more complex pipeline rather than in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inaccurate Supervision\n",
    "\n",
    "<img src=\"images/inaccurate_supervision.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Inaccurate supervision occurs when the labels provided in the training data contain errors or noise. This means some of the \"ground truth\" labels used to train the model are incorrect.\n",
    "\n",
    "Formally, it is identical to the formulation of fully supervised learning, but you can't trust the $y_i$ labels.\n",
    "We can model the noise in the labels as a transition matrix $T$ that describes the probability of flipping a label from one class to another, hence, we can estimate the real label as $\\tilde{y} = T y$.\n",
    "\n",
    "- **Sources of Inaccuracy**:\n",
    "- Human error in manual labeling.\n",
    "- Faulty automated labeling processes.\n",
    "- Built-In ambiguity in the task.\n",
    "- Deliberate noise injection.\n",
    "\n",
    "- **Types of Label Noise**:\n",
    "1. **Random Noise**:\n",
    "- Labels are randomly flipped or misassigned.\n",
    "- For binary classification, the noise transition matrix can be represented as:\n",
    "$$ T = \\begin{bmatrix}\n",
    "1-\\rho_1 & \\rho_2 \\\\\n",
    "\\rho_1 & 1-\\rho_2\n",
    "\\end{bmatrix} $$\n",
    "where $\\rho_1$ and $\\rho_2$ are the probabilities of flipping labels from 0 to 1 and 1 to 0, respectively.\n",
    "\n",
    "2. **Systematic Noise**:\n",
    "- Errors follow a pattern, often due to consistent misunderstandings or biases.\n",
    "- Can be modeled as a function of the true label:\n",
    "$$ P(\\tilde{y} | y) = g(y) $$\n",
    "where $\\tilde{y}$ is the observed (noisy) label and $y$ is the true label.\n",
    "\n",
    "3. **Instance-Dependent Noise**:\n",
    "- The likelihood of a label being incorrect depends on the features of the instance.\n",
    "- Can be modeled as:\n",
    "$$ P(\\tilde{y} | y, x) = h(y, x) $$\n",
    "where $x$ represents the features of the instance.\n",
    "\n",
    "- **Challenges**:\n",
    "- Risk of the model learning and amplifying errors in the training data.\n",
    "- Difficulty in distinguishing between true patterns and noise.\n",
    "- Potential for overfitting to noisy labels.\n",
    "- Reduced model performance and generalization ability.\n",
    "\n",
    "- **Importance in Real-World Applications**:\n",
    "- Most real-world datasets contain some degree of label noise.\n",
    "- Understanding and addressing inaccurate supervision is crucial for developing reliable machine learning models.\n",
    "- Particularly important in fields like medical diagnosis or autonomous driving where errors can have serious consequences.\n",
    "\n",
    "- **Research Directions**:\n",
    "- Developing better methods to estimate the noise transition matrix $T$.\n",
    "- Creating more robust loss functions that account for label noise, e.g., by incorporating the estimated noise rates: $ \\mathcal{L}_{robust}(\\theta) = \\mathbb{E}_{(x,\\tilde{y})}[\\ell(f_\\theta(x), \\tilde{y}) | T] $\n",
    "- Exploring theoretical bounds on learning under different noise models.\n",
    "- Confident learning: learning with noisy labels by leveraging the confidence of the model on the training data.\n",
    "\n",
    "\n",
    "> **Focus**: While we'll focus primarily on incomplete and inaccurate supervision, the concepts are similar for inexact supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overcoming the Unavailability of Labels: Weak Supervision\n",
    "\n",
    "Weak supervision is a powerful technique for addressing the challenge of limited labeled data in machine learning. This approach leverages domain knowledge and heuristics to create large-scale labeled datasets efficiently.\n",
    "\n",
    "### Key Concepts of Weak Supervision\n",
    "\n",
    "1. **Programmatic Labeling**:\n",
    "- Labels are generated through heuristics that encapsulate domain expertise.\n",
    "- These heuristics act as labeling functions, automatically assigning labels to data points.\n",
    "\n",
    "2. **Weak Labels to Strong Classifiers**:\n",
    "- Classifiers trained on weak labels can generalize beyond the specific patterns in the heuristics.\n",
    "- This generalization ability is crucial for capturing complex relationships in the data.\n",
    "\n",
    "3. **Quantity vs. Quality Trade-off**:\n",
    "- Typically, twice as much weakly labeled data is needed to match the performance of manually annotated datasets.\n",
    "- However, the cost-efficiency of weak labeling often outweighs this requirement.\n",
    "\n",
    "4. **Scalability**:\n",
    "- A significant advantage of weak supervision is its scalability.\n",
    "- The cost difference between generating 1 or 1 million labels is minimal, making it highly efficient for large datasets.\n",
    "\n",
    "### Effectiveness of Weak Supervision\n",
    "\n",
    "Empirical evidence supports the efficacy of weak supervision:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/ws1.png\" width=\"70%\" height=\"70%\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/ws2.png\" width=\"70%\" height=\"70%\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"images/ws3.png\" width=\"70%\" height=\"70%\">\n",
    "</div>\n",
    "\n",
    "These images demonstrate that weak supervision can achieve comparable or even superior performance to traditional supervised learning in various tasks.\n",
    "\n",
    "### Aggregating Noisy Labels\n",
    "\n",
    "A critical aspect of weak supervision is combining multiple, potentially noisy labeling sources:\n",
    "\n",
    "1. **Simple Methods**:\n",
    "- Majority voting is a straightforward approach but may not capture complex relationships between labeling functions.\n",
    "\n",
    "2. **Advanced Techniques**:\n",
    "- Graph neural networks and matrix completion methods offer more sophisticated aggregation.\n",
    "- These techniques can model elaborate dependencies and correlations among labeling functions.\n",
    "\n",
    "3. **Unsupervised Accuracy Estimation**:\n",
    "- It's possible to estimate the accuracy and correlations of heuristics without ground truth labels.\n",
    "- This capability is crucial for assessing the reliability of weak labels.\n",
    "\n",
    "4. **Practical Implementation**:\n",
    "- Typically, a small set (400-600) of manually labeled observations is used to calibrate and validate the weak labeling process.\n",
    "- This calibration set helps in refining heuristics and assessing their performance.\n",
    "\n",
    "5. **Probabilistic Labeling**:\n",
    "- The aggregation process results in a single probabilistic label for each observation.\n",
    "- This probabilistic approach captures the uncertainty innate in weak labeling.\n",
    "\n",
    "### Reliability of Weakly Labeled Datasets\n",
    "\n",
    "An important question arises: Can we trust weakly labeled datasets? This inquiry leads to a more fundamental question about the reliability of human-annotated datasets.\n",
    "\n",
    "> **Key Insight**: Even widely used benchmark datasets contain significant labeling errors.\n",
    "\n",
    "Examples of label error rates in popular datasets ([Northcutt et al, 2021](http://arxiv.org/abs/2103.14749)):\n",
    "- CIFAR-100: 5.85%\n",
    "- ImageNet: 5.83%\n",
    "- Google QuickDraw: 10.12%\n",
    "- IMDB Reviews: 2.9%\n",
    "- Amazon Reviews: 3.9%\n",
    "\n",
    "These findings underscore the need for techniques to automatically detect and correct annotation errors, regardless of whether the labels come from human annotators or weak supervision pipelines.\n",
    "\n",
    "### Theoretical Foundation\n",
    "\n",
    "The effectiveness of weak supervision and error detection is grounded in the non-random nature of label noise. As demonstrated by [Angluin and Laird (1988)](https://dl.acm.org/doi/10.1023/A%3A1022873112823):\n",
    "\n",
    "$$ P(\\tilde{\\mathcal{y}}_\\text{ tree photo} \\mid \\mathcal{y^*}_\\text{flower photo}) > P(\\tilde{\\mathcal{y}}_\\text{ tree photo} \\mid \\mathcal{y^*}_\\text{computer photo}) $$\n",
    "\n",
    "This inequality illustrates that mislabeling is more likely between similar classes (e.g., tree and flower) than dissimilar ones (e.g., tree and computer).\n",
    "\n",
    "### Real-World Application\n",
    "\n",
    "I've had a practical example of weak supervision's effectiveness comes from a project for the Brazilian National Council of Justice and the United Nations Development Programme:\n",
    "\n",
    "- **Scope**: Legal data classification for environmental crimes\n",
    "- **Scale**: 135,668 data points labeled across 20 classification tasks\n",
    "- **Efficiency**: Completed within days using a single legal expert to design labeling functions\n",
    "- **Performance**: Our labels where correct within the 93-100% range, which is better than most benchmark datasets from the [Northcutt et al, 2021](http://arxiv.org/abs/2103.14749) study above.\n",
    "\n",
    "This case study demonstrates the power of weak supervision in rapidly generating large-scale labeled datasets in specialized domains with minimal expert involvement.\n",
    "\n",
    "### Asymptotic Scaling\n",
    "\n",
    "- [Ratner et al](http://arxiv.org/abs/1810.02840) show that, as the number of unlabeled data points $ \\mathcal{n} $ increases, the generalization error decreases at a rate proportional to $ \\mathcal{n}^{-\\frac{1}{2}} $.\n",
    "- This scaling behavior is significant because it matches the rate found in traditional supervised learning, where the generalization error also typically scales as $ \\mathcal{n}^{-\\frac{1}{2}} $ with respect to the number of labeled data points.\n",
    "- The key result is that even though you are primarily using unlabeled data (which has been labeled through the label model $ \\hat{\\mu} $), you achieve the same asymptotic error scaling as if you were using labeled data directly.\n",
    "- This finding is valuable because it suggests that effective use of unlabeled data, when combined with a robust label model, can yield a strong predictive performance similar to traditional supervised learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the three key principles of Data-Centric AI?\n",
    "\n",
    "2. How does the Data-Centric approach differ from the conventional model-centric approach in AI development?\n",
    "\n",
    "3. Why is programmatic labeling important in Data-Centric AI?\n",
    "\n",
    "4. What role do Subject Matter Experts (SMEs) play in Data-Centric AI projects?\n",
    "\n",
    "5. What are the three primary types of weak supervision?\n",
    "\n",
    "6. How does incomplete supervision differ from inaccurate supervision?\n",
    "\n",
    "7. What is the typical trade-off between quantity and quality in weak supervision?\n",
    "\n",
    "8. How does the asymptotic scaling of weak supervision compare to traditional supervised learning?\n",
    "\n",
    "9. What challenge does manual data labeling present in real-world AI applications?\n",
    "\n",
    "10. How effective is weak supervision compared to traditional supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell.`\n",
    "\n",
    "<!-- 1. The three key principles of Data-Centric AI are: 1) It centers around data as the primary driver of AI success, 2) It needs to be programmatic to overcome limitations of manual labeling, and 3) It requires the inclusion of subject matter expertise in the development process.\n",
    "\n",
    "2. The Data-Centric approach focuses on data quality and quantity as the key drivers of AI success, whereas the conventional model-centric approach primarily focuses on designing and optimizing algorithms and model architectures.\n",
    "\n",
    "3. Programmatic labeling is important because it allows for scalable, efficient, and adaptable data labeling, overcoming the limitations of manual labeling such as cost, time, and the ability to update labels as information evolves.\n",
    "\n",
    "4. Subject Matter Experts (SMEs) are crucial in Data-Centric AI projects as they provide deep domain knowledge, help in defining project objectives, assist in data interpretation, and contribute to feature engineering and model evaluation.\n",
    "\n",
    "5. The three primary types of weak supervision are incomplete supervision, inexact supervision, and inaccurate supervision.\n",
    "\n",
    "6. Incomplete supervision occurs when only a subset of the training data is labeled, while inaccurate supervision refers to situations where the provided labels contain errors or noise.\n",
    "\n",
    "7. In weak supervision, typically twice as much weakly labeled data is needed to match the performance of manually annotated datasets. However, the cost-efficiency of weak labeling often outweighs this requirement.\n",
    "\n",
    "8. The asymptotic scaling of weak supervision matches that of traditional supervised learning, with generalization error decreasing at a rate proportional to n^(-1/2) as the number of unlabeled data points increases.\n",
    "\n",
    "9. Manual data labeling presents challenges in scalability, cost efficiency, time constraints, and the need for specialized knowledge in domain-specific tasks. It's often impractical for large-scale or sensitive data applications.\n",
    "\n",
    "10. Weak supervision can achieve comparable or even superior performance to traditional supervised learning in various tasks, as demonstrated by empirical evidence and real-world applications. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
